{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "--coPw393eMW",
        "outputId": "3002de16-fb7e-4ce1-ff6e-0a7e89fb8a64"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "PortAudio library not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-f3afbb62b126>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msounddevice\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfftpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sounddevice.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PortAudio library not found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0m_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: PortAudio library not found"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import sounddevice as sd\n",
        "import librosa as lb\n",
        "from scipy.fftpack import fft, ifft, dct\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading and labeling input <br>\n",
        "1) Read sound files <br>\n",
        "2) Add label to read sound files as tuple (sound, fs, label) for each file: 1 for car, 0 for bus\n",
        "\n"
      ],
      "metadata": {
        "id": "yJv64UsL4PiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio_files(car_dir, bus_dir):\n",
        "    \"\"\"\n",
        "    Load audio files from specified car and bus directories\n",
        "\n",
        "    Args:\n",
        "        car_dir (str): Path to directory containing car audio files\n",
        "        bus_dir (str): Path to directory containing bus audio files\n",
        "\n",
        "    Returns:\n",
        "        tuple: Lists of car and bus audio data as (audio_data, sample_rate, label)\n",
        "    \"\"\"\n",
        "    car = []  # [(sound, fs, label)]\n",
        "    bus = []  # [(sound, fs, label)]\n",
        "\n",
        "    # Load car audio files and label as 1\n",
        "    for filename in os.listdir(car_dir):\n",
        "        if filename.endswith(('.wav', '.WAV')):\n",
        "            file_path = os.path.join(car_dir, filename)\n",
        "            car_audio, car_sr = sf.read(file_path)\n",
        "            car.append((car_audio, car_sr, 1))\n",
        "\n",
        "    # Load bus audio files and label as 0\n",
        "    for filename in os.listdir(bus_dir):\n",
        "        if filename.endswith(('.wav', '.WAV')):\n",
        "            file_path = os.path.join(bus_dir, filename)\n",
        "            bus_audio, bus_sr = sf.read(file_path)\n",
        "            bus.append((bus_audio, bus_sr, 0))\n",
        "\n",
        "    print(f'Loaded {len(car)} car audios and {len(bus)} bus audios.')\n",
        "    return car, bus\n"
      ],
      "metadata": {
        "id": "pc6pzM4M4iKj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Training, Validation, and Testing data"
      ],
      "metadata": {
        "id": "INdvYayO4uhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_car_dir = \"dataset/car-sounds/training\"\n",
        "train_bus_dir = \"dataset/bus-sounds/training\"\n",
        "train_car, train_bus = load_audio_files(train_car_dir, train_bus_dir)\n",
        "\n",
        "# Load validation data\n",
        "val_car_dir = \"dataset/car-sounds/validation\"\n",
        "val_bus_dir = \"dataset/bus-sounds/validation\"\n",
        "val_car, val_bus = load_audio_files(val_car_dir, val_bus_dir)\n",
        "\n",
        "# Load test data\n",
        "test_car_dir = \"dataset/car-sounds/testing\"\n",
        "test_bus_dir = \"dataset/bus-sounds/testing\"\n",
        "test_car, test_bus = load_audio_files(test_car_dir, test_bus_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "uB7lAc284puR",
        "outputId": "156f2e08-94e5-43a4-d673-cdcd5eeb0d17"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-77f1c486c160>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_car_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/car-sounds/training\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_bus_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataset/bus-sounds/training\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_car\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_audio_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_car_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_bus_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-24e20904b4b4>\u001b[0m in \u001b[0;36mload_audio_files\u001b[0;34m(car_dir, bus_dir)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Load car audio files and label as 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.WAV'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Features Method\n"
      ],
      "metadata": {
        "id": "kTlwJDKN4tqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_feature(audios, Fs, audio_length, n_fft, win_size, hop_size, n_mels, window_name=\"hamming\"):\n",
        "    features = []\n",
        "    for i in range(len(audios)):\n",
        "        feature = dict()\n",
        "        audio, fs, label = audios[i]\n",
        "\n",
        "        # Check if audio is a 1d array\n",
        "        if (audio.ndim != 1):\n",
        "            audio = np.mean(audio, axis=1)\n",
        "\n",
        "        # Resample the audio to a fixed sampling rate Fs\n",
        "        if fs != Fs:\n",
        "            audio = lb.resample(audio, orig_sr=fs, target_sr=Fs)\n",
        "\n",
        "        # Trim the audio to a fixed length of 5 seconds\n",
        "        if len(audio) != audio_length:\n",
        "            audio = audio[:audio_length]\n",
        "\n",
        "        # Add checks for valid audio data\n",
        "        if len(audio) == 0 or np.any(np.isnan(audio)) or np.any(np.isinf(audio)):\n",
        "            print(f\"Skipping invalid audio sample\")\n",
        "            continue\n",
        "\n",
        "        # Safer normalization\n",
        "        if np.max(audio) != np.min(audio):\n",
        "            audio = 2 * ((audio - np.min(audio)) / (np.max(audio) - np.min(audio))) - 1\n",
        "        else:\n",
        "            audio = np.zeros_like(audio)\n",
        "\n",
        "        # 2.1) Mel spectrogram in log scale\n",
        "        mel_spectro = lb.feature.melspectrogram(\n",
        "            y=audio, sr=Fs, n_fft=n_fft, n_mels=n_mels,\n",
        "            win_length=win_size, window=window_name, hop_length=hop_size)\n",
        "\n",
        "        mel_spectro_db = lb.power_to_db(mel_spectro, ref=np.max)\n",
        "\n",
        "        # 2.2) MFCC\n",
        "        #mfcc = lb.feature.mfcc(\n",
        "        #    y=audio, sr=Fs, n_mfcc=n_mels, n_mels=n_mels, n_fft=n_fft,\n",
        "        #    win_length=win_size, window=\"hamming\", hop_length=hop_size)\n",
        "        mfcc = dct(mel_spectro_db, axis=0)\n",
        "\n",
        "        # 2.3) RMS\n",
        "        rms = lb.feature.rms(y=audio, frame_length=audio_length//hop_size, hop_length=hop_size)\n",
        "\n",
        "        # 2.4) zcr\n",
        "        zcr = lb.feature.zero_crossing_rate(y=audio, frame_length=audio_length//hop_size, hop_length=hop_size)\n",
        "\n",
        "        # Append the features to car_features\n",
        "        feature[\"mel\"] = mel_spectro_db\n",
        "        feature[\"mfcc\"] = mfcc\n",
        "        feature[\"rms\"] = rms\n",
        "        feature[\"zcr\"] = zcr\n",
        "\n",
        "        features.append((feature, label))\n",
        "\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "Uoyc7tID4_KG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing the data\n",
        "1) Resample the audio signal to a fixed sampling rate<br>\n",
        "2) Normalize the dataset<br>\n",
        "3) Feature extractions:<br>\n",
        "  3.1) Mel Spectrogram<br>\n",
        "  3.2) MFCC<br>\n",
        "  3.3) Energy: RMS<br>\n",
        "  3.4) Zero-crossing rate (zcr)<br>\n",
        "output example: list[ (dict(mel spectrogram, MFCC, RMS, zcr), label), ...]"
      ],
      "metadata": {
        "id": "IbS5jGLE5EtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Fs = 44100\n",
        "L = Fs*5\n",
        "n_fft = 2048\n",
        "win_size = 1024\n",
        "hop_size = win_size//2\n",
        "n_mels = 128\n",
        "\n",
        "# Extract features for training data\n",
        "train_car_features = extract_feature(audios=train_car, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "train_bus_features = extract_feature(audios=train_bus, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "\n",
        "# Extract features for validation data\n",
        "val_car_features = extract_feature(audios=val_car, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "val_bus_features = extract_feature(audios=val_bus, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "\n",
        "# Extract features for testing data\n",
        "test_car_features = extract_feature(audios=test_car, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "test_bus_features = extract_feature(audios=test_bus, Fs=Fs, audio_length=L, n_fft=n_fft, win_size=win_size, hop_size=hop_size, n_mels=n_mels)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Feature extraction done.\")\n",
        "print(f'Train data: usable car audios: {len(train_car_features)}, usable bus audios: {len(train_bus_features)}')\n",
        "print(f'Validation data: usable car audios: {len(val_car_features)}, usable bus audios: {len(val_bus_features)}')\n",
        "print(f'Test data: usable car audios: {len(test_car_features)}, usable bus audios: {len(test_bus_features)}')\n",
        "print(f'train_car_features[0] ->', train_car_features[0][0].keys(), f', label={train_car_features[0][1]}', \"\\n\")\n",
        "\n",
        "# Combine features for each dataset separately\n",
        "train_features = train_car_features + train_bus_features\n",
        "val_features = val_car_features + val_bus_features\n",
        "test_features = test_car_features + test_bus_features\n"
      ],
      "metadata": {
        "id": "AoyM12WM5AUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prepare training data with error handling and debugging"
      ],
      "metadata": {
        "id": "T96attjH5efl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "max_length = 0  # Track the maximum length of feature vectors\n",
        "\n",
        "for features in train_features:\n",
        "    try:\n",
        "        feature_vector = []\n",
        "        for v in features[0].values():\n",
        "            if isinstance(v, np.ndarray):\n",
        "                feature_vector.append(v.flatten())\n",
        "            else:\n",
        "                feature_vector.append(np.array([v]))\n",
        "        concatenated_vector = np.concatenate(feature_vector)\n",
        "        X_train.append(concatenated_vector)\n",
        "        max_length = max(max_length, len(concatenated_vector))\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing feature: {features[0].keys()}\")\n",
        "        print(f\"Feature shapes: {[v.shape if isinstance(v, np.ndarray) else type(v) for v in features[0].values()]}\")\n",
        "        raise e\n",
        "\n",
        "# Pad feature vectors to ensure consistent length\n",
        "X_train = np.array([np.pad(x, (0, max_length - len(x)), 'constant') for x in X_train])\n",
        "y_train = np.array([label for _, label in train_features])\n",
        "\n",
        "# Create labels for validation data\n",
        "y_val = np.array([label for _, label in val_features])\n",
        "\n",
        "# Create labels for test data\n",
        "y_test = np.array([label for _, label in test_features])\n",
        "\n",
        "# Apply the same pattern for validation and test data\n",
        "X_val = []\n",
        "for features in val_features:\n",
        "    feature_vector = []\n",
        "    for v in features[0].values():\n",
        "        if isinstance(v, np.ndarray):\n",
        "            feature_vector.append(v.flatten())\n",
        "        else:\n",
        "            feature_vector.append(np.array([v]))\n",
        "    concatenated_vector = np.concatenate(feature_vector)\n",
        "    X_val.append(np.pad(concatenated_vector, (0, max_length - len(concatenated_vector)), 'constant'))\n",
        "X_val = np.array(X_val)\n",
        "\n",
        "X_test = []\n",
        "for features in test_features:\n",
        "    feature_vector = []\n",
        "    for v in features[0].values():\n",
        "        if isinstance(v, np.ndarray):\n",
        "            feature_vector.append(v.flatten())\n",
        "        else:\n",
        "            feature_vector.append(np.array([v]))\n",
        "    concatenated_vector = np.concatenate(feature_vector)\n",
        "    X_test.append(np.pad(concatenated_vector, (0, max_length - len(concatenated_vector)), 'constant'))\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "cwKm_mNv5aK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Applying Models"
      ],
      "metadata": {
        "id": "UuCBGHVf5pC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. SVM Model"
      ],
      "metadata": {
        "id": "OZ91Z0e95smH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train SVM model\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',  # Try 'linear', 'poly', or 'sigmoid'\n",
        "    C=1.0,        # Try different values like 0.1, 1, 10, 100\n",
        "    gamma='scale', # Try 'auto' or specific values\n",
        "    class_weight='balanced', # Add this to handle class imbalance\n",
        "    random_state=42\n",
        ")\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_predictions = svm_model.predict(X_val_scaled)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f} or {val_accuracy*100:.2f}%\")\n",
        "print(\"\\nValidation Classification Report:\")\n",
        "print(classification_report(y_val, val_predictions,\n",
        "                          target_names=['Bus', 'Car'],\n",
        "                          zero_division=0))\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_predictions = svm_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} or {test_accuracy*100:.2f}%\")\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(y_test, test_predictions,\n",
        "                          target_names=['Bus', 'Car'],\n",
        "                          zero_division=0))\n",
        "print(\"#\"*100)\n",
        "\n",
        "\n",
        "# Also, let's add some diagnostic information\n",
        "print(\"\\nData Distribution:\")\n",
        "print(f\"Training set - Bus: {sum(y_train == 0)}, Car: {sum(y_train == 1)}\")\n",
        "print(f\"Validation set - Bus: {sum(y_val == 0)}, Car: {sum(y_val == 1)}\")\n",
        "print(f\"Test set - Bus: {sum(y_test == 0)}, Car: {sum(y_test == 1)}\")\n"
      ],
      "metadata": {
        "id": "U-Oktcij5odV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Applying Random Forest"
      ],
      "metadata": {
        "id": "PgQgwMBx56fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_predictions = rf_model.predict(X_val_scaled)\n",
        "val_accuracy = accuracy_score(y_val, val_predictions)\n",
        "print(\"\\nValidation Set Performance:\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f} or {val_accuracy*100:.2f}%\")\n",
        "print(\"\\nValidation Classification Report:\")\n",
        "print(classification_report(y_val, val_predictions,\n",
        "                          target_names=['Bus', 'Car'],\n",
        "                          zero_division=0))\n",
        "\n",
        "# Final evaluation on test set\n",
        "test_predictions = rf_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(\"\\nTest Set Performance:\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} or {test_accuracy*100:.2f}%\")\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_report(y_test, test_predictions,\n",
        "                          target_names=['Bus', 'Car'],\n",
        "                          zero_division=0))\n"
      ],
      "metadata": {
        "id": "0dMtQklY59Q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plot the learning curves"
      ],
      "metadata": {
        "id": "-u2zFa106sTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curves(model, X_train, y_train, X_val, y_val, X_test, y_test, model_name=\"\"):\n",
        "    \"\"\"\n",
        "    Plot learning curves for training, validation, and test sets\n",
        "    \"\"\"\n",
        "    train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "    train_scores_acc = []\n",
        "    val_scores_acc = []\n",
        "    test_scores_acc = []\n",
        "\n",
        "    train_scores_precision = []\n",
        "    val_scores_precision = []\n",
        "    test_scores_precision = []\n",
        "\n",
        "    train_scores_recall = []\n",
        "    val_scores_recall = []\n",
        "    test_scores_recall = []\n",
        "\n",
        "    # Get indices for each class\n",
        "    class_0_idx = np.where(y_train == 0)[0]\n",
        "    class_1_idx = np.where(y_train == 1)[0]\n",
        "\n",
        "    for size in train_sizes:\n",
        "        try:\n",
        "            # Calculate how many samples we need from each class\n",
        "            n_samples = int(len(X_train) * size)\n",
        "            n_samples_per_class = n_samples // 2\n",
        "\n",
        "            # Get balanced subset of indices\n",
        "            subset_0_idx = np.random.choice(class_0_idx, n_samples_per_class, replace=False)\n",
        "            subset_1_idx = np.random.choice(class_1_idx, n_samples_per_class, replace=False)\n",
        "            subset_idx = np.concatenate([subset_0_idx, subset_1_idx])\n",
        "\n",
        "            # Create balanced subset\n",
        "            X_train_subset = X_train[subset_idx]\n",
        "            y_train_subset = y_train[subset_idx]\n",
        "\n",
        "            # Train model on subset\n",
        "            model.fit(X_train_subset, y_train_subset)\n",
        "\n",
        "            # Get predictions\n",
        "            predictions_train = model.predict(X_train_subset)\n",
        "            predictions_val = model.predict(X_val)\n",
        "            predictions_test = model.predict(X_test)\n",
        "\n",
        "            # Calculate scores\n",
        "            train_scores_acc.append(accuracy_score(y_train_subset, predictions_train))\n",
        "            val_scores_acc.append(accuracy_score(y_val, predictions_val))\n",
        "            test_scores_acc.append(accuracy_score(y_test, predictions_test))\n",
        "\n",
        "            train_scores_precision.append(precision_score(y_train_subset, predictions_train, zero_division=0))\n",
        "            val_scores_precision.append(precision_score(y_val, predictions_val, zero_division=0))\n",
        "            test_scores_precision.append(precision_score(y_test, predictions_test, zero_division=0))\n",
        "\n",
        "            train_scores_recall.append(recall_score(y_train_subset, predictions_train, zero_division=0))\n",
        "            val_scores_recall.append(recall_score(y_val, predictions_val, zero_division=0))\n",
        "            test_scores_recall.append(recall_score(y_test, predictions_test, zero_division=0))\n",
        "        except Exception as e:\n",
        "            print(f\"Error at size {size}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    x_values = train_sizes * 100\n",
        "    fig, ax = plt.subplots(3, figsize=(10, 8))\n",
        "    ax[0].plot(x_values, train_scores_acc, label='Training', marker='o')\n",
        "    ax[0].plot(x_values, val_scores_acc, label='Validation', marker='s')\n",
        "    ax[0].plot(x_values, test_scores_acc, label='Test', marker='^')\n",
        "    #ax[0].set_xlabel('Percentage of Training Data')\n",
        "    ax[0].set_ylabel('Accuracy Score')\n",
        "    ax[0].set_title(f'Learning Curves of {model_name}')\n",
        "    ax[0].legend(fancybox=True, framealpha=0.5)\n",
        "    ax[0].grid(True)\n",
        "    ax[1].plot(x_values, train_scores_precision, label='Training', marker='o')\n",
        "    ax[1].plot(x_values, val_scores_precision, label='Validation', marker='s')\n",
        "    ax[1].plot(x_values, test_scores_precision, label='Test', marker='^')\n",
        "    #ax[1].set_xlabel('Percentage of Training Data')\n",
        "    ax[1].set_ylabel('Precision Score')\n",
        "    ax[1].legend(fancybox=True, framealpha=0.5)\n",
        "    ax[1].grid(True)\n",
        "    ax[2].plot(x_values, train_scores_recall, label='Training', marker='o')\n",
        "    ax[2].plot(x_values, val_scores_recall, label='Validation', marker='s')\n",
        "    ax[2].plot(x_values, test_scores_recall, label='Test', marker='^')\n",
        "    ax[2].set_xlabel('Percentage of Training Data')\n",
        "    ax[2].set_ylabel('Recall Score')\n",
        "    ax[2].legend(fancybox=True, framealpha=0.5)\n",
        "    ax[2].grid(True)\n",
        "    fig.tight_layout()\n",
        "    plt.savefig(f'{\"_\".join(model_name.lower().split(\" \"))}.png')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "oAMDvsga6vX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curves for SVM model\n",
        "print(\"\\nPlotting Learning Curves for SVM Model:\")\n",
        "plot_learning_curves(\n",
        "    SVC(kernel='rbf', C=1.0, gamma='scale', class_weight='balanced', random_state=42),\n",
        "    X_train_scaled, y_train,\n",
        "    X_val_scaled, y_val,\n",
        "    X_test_scaled, y_test,\n",
        "    model_name=\"Support Vector Machine\"\n",
        ")\n",
        "\n",
        "# Plot learning curves for Random Forest model\n",
        "print(\"\\nPlotting Learning Curves for Random Forest Model:\")\n",
        "plot_learning_curves(\n",
        "    RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    X_train_scaled, y_train,\n",
        "    X_val_scaled, y_val,\n",
        "    X_test_scaled, y_test,\n",
        "    model_name=\"Random Forest Classifier\"\n",
        ")"
      ],
      "metadata": {
        "id": "5pM73cU-67jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Features Plots"
      ],
      "metadata": {
        "id": "AvmuwnN27B9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_plots(X_train, y_train, feature_indices, feature_names):\n",
        "    \"\"\"\n",
        "    Create distribution plots, boxplots, and pair plots for audio features\n",
        "    \"\"\"\n",
        "    # Select specific features to plot\n",
        "    selected_features = X_train[:, feature_indices]\n",
        "    df = pd.DataFrame(selected_features, columns=feature_names)\n",
        "    df['Label'] = ['Car' if label == 1 else 'Bus' for label in y_train]\n",
        "\n",
        "    # 1. Feature Distribution Plots\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for idx, feature in enumerate(feature_names, 1):\n",
        "        plt.subplot(2, 2, idx)\n",
        "        sns.histplot(data=df, x=feature, hue='Label', kde=True)\n",
        "        plt.title(f'Distribution of {feature}', fontsize=12, pad=10)\n",
        "        plt.xlabel(f'{feature} Value', fontsize=10)\n",
        "        plt.ylabel('Frequency', fontsize=10)\n",
        "    plt.suptitle('Feature Distributions for Car and Bus Audio Classification', fontsize=14, y=1.02)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout\n",
        "    plt.savefig('feature_distributions.png', bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # 2. Box Plots\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for idx, feature in enumerate(feature_names, 1):\n",
        "        plt.subplot(2, 2, idx)\n",
        "        sns.boxplot(x='Label', y=feature, data=df)\n",
        "        plt.title(f'Boxplot of {feature}', fontsize=12, pad=10)\n",
        "        plt.xlabel('Vehicle Type', fontsize=10)\n",
        "        plt.ylabel(f'{feature} Value', fontsize=10)\n",
        "    plt.suptitle('Feature Boxplots for Car and Bus Audio Classification', fontsize=14, y=1.02)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout\n",
        "    plt.savefig('feature_boxplots.png', bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Pair Plot\n",
        "    pair_plot = sns.pairplot(df, hue='Label', diag_kind='kde')\n",
        "    pair_plot.fig.suptitle('Feature Relationships in Car and Bus Audio Classification',\n",
        "                          fontsize=14, y=1.02)\n",
        "    plt.subplots_adjust(top=0.9)  # Adjust layout\n",
        "    plt.savefig('feature_pairplot.png', bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Define actual feature names based on audio characteristics\n",
        "feature_names = ['MFCC (Mel Frequency Cepstral Coefficients)',\n",
        "                'Mel Spectrogram Energy',\n",
        "                'RMS Energy',\n",
        "                'Zero Crossing Rate']\n",
        "\n",
        "# Call the function with the first 4 features\n",
        "create_feature_plots(X_train_scaled, y_train, list(range(4)), feature_names)\n",
        "\n",
        "# Create DataFrame with features for statistics\n",
        "selected_features = X_train_scaled[:, :4]  # First 4 features\n",
        "df = pd.DataFrame(selected_features, columns=['MFCC', 'Mel Spectrogram', 'RMS', 'ZCR'])\n",
        "df['Label'] = ['Car' if label == 1 else 'Bus' for label in y_train]\n",
        "\n",
        "print(\"\\nFeature Statistics:\")\n",
        "df_stats = df.groupby('Label').describe()\n",
        "print(df_stats)\n"
      ],
      "metadata": {
        "id": "qXUp_wk67E_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}